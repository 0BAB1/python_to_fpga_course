{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a71a8839-7c58-4862-a5f0-0f7e97085918",
   "metadata": {},
   "source": [
    "# PART 1\n",
    "\n",
    "After creating the docker environement,\n",
    "\n",
    "The goal of this lab is to create a MNIST Fasion model in pytorch and experiment with the different parameters\n",
    "\n",
    "Then, we will do the same model but fully quantized and start adapting it for FINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a09c1a7-e82e-4d14-bced-29aaf340638c",
   "metadata": {},
   "source": [
    "## Base model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e9dec1-299c-45ec-bc1a-41d4825fea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9651dd1-25d9-4c48-8e02-08c28d29fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    #transforms.Normalize((0.5,), (0.5,))  # Normalize the tensor with mean and std\n",
    "]);\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data',  # Directory to save the dataset\n",
    "    train=True,  # Load the training set\n",
    "    download=True,  # Download the dataset if it doesn't exist\n",
    "    transform=transform  # Apply the defined transformations\n",
    ");\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,  # Load the test set\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb48f47-1369-4f87-8c9b-c0e29a8de5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min :  0.0  /// Max :  0.78039217\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image, label = train_dataset[5]\n",
    "image = np.array(image).squeeze()\n",
    "print(\"Min : \", np.min(image[0]), \" /// Max : \", np.max(image[0]))\n",
    "# plot the sample\n",
    "\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccdce0f7-c128-48f5-956e-7174818139d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# Create a data loader for the training set\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,  # Number of samples per batch\n",
    "    shuffle=True  # Shuffle the data\n",
    ")\n",
    "\n",
    "# Create a data loader for the test set\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False  # No need to shuffle the test data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0f87bc-cfa0-4d45-9ed3-eddff267ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135060a6-6f2f-4cee-a32e-3881d985b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden1 = 64\n",
    "hidden2 = 64\n",
    "num_classes = 10\n",
    "\n",
    "class SimpleFCModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleFCModel, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.relu = nn.ReLU()                          # Activation function\n",
    "        self.fc1 = nn.Linear(input_size, hidden1)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2) # Second hidden layer\n",
    "        self.fc3 = nn.Linear(hidden2, num_classes) # Output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559a5697-2f00-4a5e-8f5f-119ea87351d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleFCModel(\n",
       "  (relu): ReLU()\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleFCModel()\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "779b5632-3ac5-41da-a155-63f7c4d343a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.3506\n",
      "Epoch [2/5], Loss: 0.3629\n",
      "Epoch [3/5], Loss: 0.4885\n",
      "Epoch [4/5], Loss: 0.4001\n",
      "Epoch [5/5], Loss: 0.2238\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = torch.reshape(images, (batch_size, input_size))\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/5], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fb5c432-a6e6-4668-87e9-98cbd7799974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 86.38\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = torch.reshape(images, (batch_size, input_size))\n",
    "        out = model(images)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(\"accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1648a989-431b-418d-9dbf-118ca52aa7e1",
   "metadata": {},
   "source": [
    "# PART 2\n",
    "\n",
    "This part is about creating a quantized version of the model and adapting it to finn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab5b0a0-9cfd-41c7-99cc-3c2d3365cbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): QuantIdentity(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): QuantLinear(\n",
       "    in_features=784, out_features=64, bias=True\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): QuantLinear(\n",
       "    in_features=64, out_features=64, bias=True\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.5, inplace=False)\n",
       "  (8): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (9): QuantLinear(\n",
       "    in_features=64, out_features=10, bias=True\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (10): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from brevitas.nn import QuantLinear\n",
    "from brevitas.nn import QuantReLU\n",
    "from brevitas.nn import QuantIdentity\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "brevitas_input_size = 28 * 28\n",
    "brevitas_hidden1 = 64\n",
    "brevitas_hidden2 = 64\n",
    "brevitas_num_classes = 10\n",
    "weight_bit_width = 4\n",
    "act_bit_width = 4\n",
    "dropout_prob = 0.5\n",
    "\n",
    "#is this model fully quantized or only the wieghts, i shall dig to find out once done !\n",
    "brevitas_model = nn.Sequential(\n",
    "    QuantIdentity(bit_width=4),\n",
    "    QuantLinear(brevitas_input_size, brevitas_hidden1, bias=True, weight_bit_width=weight_bit_width),\n",
    "    nn.BatchNorm1d(brevitas_hidden1),\n",
    "    nn.Dropout(0.5),\n",
    "    QuantReLU(bit_width=act_bit_width),\n",
    "    QuantLinear(brevitas_hidden1, brevitas_hidden2, bias=True, weight_bit_width=weight_bit_width),\n",
    "    nn.BatchNorm1d(brevitas_hidden2),\n",
    "    nn.Dropout(0.5),\n",
    "    QuantReLU(bit_width=act_bit_width),\n",
    "    QuantLinear(brevitas_hidden2, brevitas_num_classes, bias=True, weight_bit_width=weight_bit_width),\n",
    "    QuantReLU(bit_width=act_bit_width)\n",
    ")\n",
    "\n",
    "brevitas_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236d85fe-986a-44f4-84d1-fce1d5591f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:1255: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1758.)\n",
      "  return super(Tensor, self).rename(names)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6448\n",
      "Epoch [2/5], Loss: 0.6147\n",
      "Epoch [3/5], Loss: 0.6063\n",
      "Epoch [4/5], Loss: 0.5514\n",
      "Epoch [5/5], Loss: 0.4500\n"
     ]
    }
   ],
   "source": [
    "# loss criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(brevitas_model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "num_epochs = 5\n",
    "brevitas_model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = torch.reshape(images, (batch_size, input_size))\n",
    "        out = brevitas_model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/5], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4d239cf-edb2-4faa-a502-d05861a156fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 86.38\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "brevitas_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = torch.reshape(images, (batch_size, input_size))\n",
    "        out = brevitas_model(images)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(\"accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a9e8ec-7a6a-41f9-a791-8a63bb58aa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min :  tensor(0.)  /// Max :  tensor(1.)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.6196, 0.8039, 0.4784, 0.5725, 0.7020, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0627, 0.3961, 0.7373, 1.0000, 0.8588, 0.6549, 0.3686,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824,\n",
      "         0.2392, 0.4235, 0.6196, 0.3137, 0.0353, 0.8235, 0.4706, 0.3137, 0.7961,\n",
      "         0.6667, 0.5059, 0.2667, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.4510, 0.5255,\n",
      "         0.4510, 0.3765, 0.3765, 0.3412, 0.4314, 0.4235, 0.3608, 0.4314, 0.3686,\n",
      "         0.3882, 0.4706, 0.5333, 0.5804, 0.4627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.3608, 0.3686, 0.3137,\n",
      "         0.3020, 0.2588, 0.3137, 0.3412, 0.2863, 0.5059, 0.3765, 0.3216, 0.3608,\n",
      "         0.3333, 0.3020, 0.3333, 0.2667, 0.5059, 0.2471, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1725, 0.3137, 0.2196, 0.2745,\n",
      "         0.3020, 0.2863, 0.2745, 0.3020, 0.3020, 0.3882, 0.3490, 0.3608, 0.3412,\n",
      "         0.3608, 0.3490, 0.3412, 0.3765, 0.4157, 0.5059, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.3020, 0.2745, 0.2863,\n",
      "         0.2667, 0.3020, 0.2667, 0.2941, 0.2863, 0.3961, 0.3216, 0.3216, 0.3490,\n",
      "         0.3608, 0.3412, 0.3686, 0.4431, 0.3333, 0.5804, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.2667, 0.3961, 0.2667,\n",
      "         0.2392, 0.2471, 0.2588, 0.2667, 0.2588, 0.4627, 0.3412, 0.3216, 0.3765,\n",
      "         0.2941, 0.3333, 0.4980, 0.4980, 0.2745, 0.6196, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.1569, 0.5804, 0.3686,\n",
      "         0.1843, 0.2196, 0.2314, 0.2667, 0.2745, 0.3686, 0.2667, 0.2667, 0.3765,\n",
      "         0.3686, 0.3137, 0.7294, 0.6078, 0.2863, 0.5529, 0.0549, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.3490, 0.0706, 0.5333, 0.7216,\n",
      "         0.0902, 0.2196, 0.2314, 0.2588, 0.2745, 0.3686, 0.2863, 0.2471, 0.3686,\n",
      "         0.4157, 0.2941, 0.8235, 0.7216, 0.2471, 0.4902, 0.1725, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2196, 0.3961, 0.1373, 0.4235, 0.8235,\n",
      "         0.1647, 0.2745, 0.2471, 0.2588, 0.2471, 0.3882, 0.3412, 0.2588, 0.3490,\n",
      "         0.3961, 0.4706, 0.9686, 0.6745, 0.1451, 0.4902, 0.3490, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1843, 0.3216, 0.2471, 0.6941, 0.4980,\n",
      "         0.1647, 0.2941, 0.2471, 0.2588, 0.2314, 0.3412, 0.3686, 0.2745, 0.3490,\n",
      "         0.4510, 0.4706, 0.6745, 0.6667, 0.3137, 0.4235, 0.2863, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.0000,\n",
      "         0.2941, 0.2667, 0.2196, 0.2588, 0.2392, 0.3137, 0.3490, 0.2667, 0.3020,\n",
      "         0.4314, 0.5176, 0.0000, 0.1176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.3137, 0.2863, 0.2392, 0.2314, 0.2118, 0.3216, 0.3686, 0.3020, 0.3020,\n",
      "         0.3961, 0.5529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0275, 0.0000, 0.0000,\n",
      "         0.3137, 0.2863, 0.2392, 0.2667, 0.2471, 0.3216, 0.3765, 0.3216, 0.3333,\n",
      "         0.4157, 0.5451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.3020, 0.2863, 0.2392, 0.2588, 0.2667, 0.3216, 0.3882, 0.3608, 0.3412,\n",
      "         0.3608, 0.5059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.3137, 0.2863, 0.2392, 0.2588, 0.2588, 0.3333, 0.3765, 0.3137, 0.2941,\n",
      "         0.4235, 0.5176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.3020, 0.2941, 0.2471, 0.2667, 0.2588, 0.3490, 0.3882, 0.3020, 0.3765,\n",
      "         0.4784, 0.4902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.3137, 0.3020, 0.2588, 0.2863, 0.2588, 0.3608, 0.4039, 0.3333, 0.3882,\n",
      "         0.3412, 0.4980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.3333, 0.2471, 0.2667, 0.2745, 0.2588, 0.3490, 0.4157, 0.3412, 0.3137,\n",
      "         0.3882, 0.5804, 0.0078, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0078,\n",
      "         0.4157, 0.3137, 0.3020, 0.3137, 0.2745, 0.3490, 0.4157, 0.3333, 0.3490,\n",
      "         0.3961, 0.5725, 0.0275, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0980,\n",
      "         0.3961, 0.2941, 0.3216, 0.3137, 0.2667, 0.4039, 0.4627, 0.3333, 0.3961,\n",
      "         0.3333, 0.5725, 0.0824, 0.0000, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.1647,\n",
      "         0.3765, 0.2863, 0.3490, 0.3490, 0.3137, 0.4157, 0.4510, 0.3765, 0.3882,\n",
      "         0.3137, 0.5725, 0.1451, 0.0000, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.2392,\n",
      "         0.3882, 0.2471, 0.3216, 0.3490, 0.2863, 0.4314, 0.4510, 0.3490, 0.3765,\n",
      "         0.3412, 0.4980, 0.1725, 0.0000, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.2000,\n",
      "         0.3961, 0.2941, 0.3490, 0.3412, 0.2588, 0.5529, 0.5059, 0.2863, 0.3608,\n",
      "         0.3137, 0.5176, 0.2314, 0.0000, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0627,\n",
      "         0.4431, 0.2941, 0.3020, 0.3882, 0.3216, 0.4980, 0.6745, 0.2588, 0.3882,\n",
      "         0.3216, 0.5255, 0.1843, 0.0000, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2196, 0.3412, 0.4784, 0.5059, 0.3333, 0.6078, 0.8510, 0.3216, 0.4627,\n",
      "         0.5529, 0.4706, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.1176, 0.2000, 0.1922, 0.2000, 0.2392, 0.2118, 0.1647,\n",
      "         0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# lets see what out data look like\n",
    "fig = plt.figure\n",
    "plt.imshow(torch.reshape(images[0],(28,28)), cmap='gray')\n",
    "plt.show()\n",
    "print(\"Min : \", torch.min(images[0]), \" /// Max : \", torch.max(images[0]))\n",
    "print(torch.reshape(images[0],(28,28)))\n",
    "# note : may do the exercice only using uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3843919-1e83-4c50-accd-3e9292cecc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantTensor(value=tensor([[-0.0287, -0.0287, -0.0000,  ...,  0.1148, -0.0287,  0.0000],\n",
      "        [ 0.0000,  0.0861,  0.0574,  ..., -0.0861, -0.0574,  0.0287],\n",
      "        [-0.0287, -0.0000,  0.0000,  ..., -0.1148,  0.0287, -0.0574],\n",
      "        ...,\n",
      "        [-0.0000, -0.0574, -0.0861,  ...,  0.1148, -0.0287, -0.0574],\n",
      "        [-0.0574,  0.0574,  0.0861,  ..., -0.0287, -0.0861, -0.0574],\n",
      "        [-0.0000,  0.0287,  0.0287,  ..., -0.1148,  0.0287, -0.0574]],\n",
      "       grad_fn=<MulBackward0>), scale=tensor(0.0287, grad_fn=<DivBackward0>), zero_point=tensor(0.), bit_width=tensor(4.), signed_t=tensor(True), training_t=tensor(False))\n",
      "tensor([[-1, -1,  0,  ...,  4, -1,  0],\n",
      "        [ 0,  3,  2,  ..., -3, -2,  1],\n",
      "        [-1,  0,  0,  ..., -4,  1, -2],\n",
      "        ...,\n",
      "        [ 0, -2, -3,  ...,  4, -1, -2],\n",
      "        [-2,  2,  3,  ..., -1, -3, -2],\n",
      "        [ 0,  1,  1,  ..., -4,  1, -2]], dtype=torch.int8)\n",
      "torch.int8\n"
     ]
    }
   ],
   "source": [
    "#lets have a quick look at the weights too\n",
    "print(brevitas_model[1].quant_weight())\n",
    "#internally, weoght are stored as float 32, here nare ways to visualize actual quantized weights :\n",
    "print(brevitas_model[1].quant_weight().int())\n",
    "print(brevitas_model[1].quant_weight().int().dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8247848d-6308-4524-984c-e15e9d1e71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model wrapper to :\n",
    "# - make sure the model can rack in bipolar data, we just saw so no need for that\n",
    "# - add a binary quantizer on the output whith bipolar behavior\n",
    "# note to myself, may have to rework that output quantizer (or just do no pre/post, also works fine\n",
    "from brevitas.nn import QuantIdentity\n",
    "\n",
    "\n",
    "class ModelForExport(nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(ModelForExport, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        \"\"\"self.qnt_output = QuantIdentity(\n",
    "            quant_type='binary', \n",
    "            scaling_impl_type='const',\n",
    "            bit_width=1, min_val=-1.0, max_val=1.0)\"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # here we could insert bipolar preprocessing\n",
    "        out= self.pretrained(x)\n",
    "        # outputs as {-1,1}\n",
    "        \"\"\"out_final = self.qnt_output(out_original)\"\"\"\n",
    "        return out\n",
    "\n",
    "model_for_export = ModelForExport(brevitas_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "058a27d4-d48a-41b4-834e-75253bb230ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 86.38\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "model_for_export.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = torch.reshape(images, (batch_size, input_size))\n",
    "        out = model_for_export(images)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(\"accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d9899-000b-4343-ac81-2c425b571519",
   "metadata": {},
   "source": [
    "# PART 3\n",
    "\n",
    "Exporting the model and visualizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11f27a3b-88c6-483e-be82-85d1ee53129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "filename = \"/tmp/finn_dev_rootmin/LAB_1.onnx\"\n",
    "filename_clean = \"/tmp/finn_dev_rootmin/LAB1_clean.onnx\"\n",
    "\n",
    "#Crete a tensor ressembling the input tensor we saw earlier\n",
    "input_a = np.random.rand(1,28*28).astype(np.float32)\n",
    "input_a = 2 * input_a - 1 # TODO ERRASE THIS\n",
    "scale = 1.0\n",
    "input_t = torch.from_numpy(input_a * scale)\n",
    "\n",
    "# Export to ONNX\n",
    "export_qonnx(\n",
    "    model_for_export, export_path=filename, input_t=input_t\n",
    ")\n",
    "\n",
    "# clean-up\n",
    "qonnx_cleanup(filename, out_file=filename_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d6f0250-5b1c-4276-9293-c29a1b112782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/tmp/finn_dev_rootmin/LAB_1.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d1c5aac8df0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7dfbd8-95ff-4b2b-8a89-9656d1436222",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(filename_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589a8d3-f069-472c-85f3-ab2480e09fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "filename_final = \"/tmp/finn_dev_rootmin/LAB1_finnonnx.onnx\"\n",
    "\n",
    "# Create a model wrapper, convert to FINN\n",
    "model = ModelWrapper(filename_clean)\n",
    "# this is because we saw the input range from -1 to 1 but may have to be reworked\n",
    "model.set_tensor_datatype(model.graph.input[0].name, DataType[\"BIPOLAR\"])\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model.save(filename_final)\n",
    "\n",
    "print(\"Model saved to %s\" % filename_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff071747-aa8c-4cac-899a-b7d3bbd92441",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(filename_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09bf3d-0802-4b3f-b686-fd649f5f6687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL VERIFICATION\n",
    "\n",
    "When creating the model from scratch and manipulating the data in different ways to adapt it to the use case, verifying the model at each step turns out to be important.\n",
    "\n",
    "During LAB2 notebook, we already verified the FINN-ONNX model, which indicates that we did the job right on our side, but what if something goes wrong in the way we apply further transformations ?\n",
    "\n",
    "To make sure we are ready for FPGA inference, verification is a very important step to avoid hours of useless hardware dubugging.\n",
    "\n",
    "Verifications convered by this notebook :\n",
    "\n",
    "- HLS layers verification using C++\n",
    "- RTL output verification using PyVerilator\n",
    "\n",
    "This notebook was based on [this example](https://github.com/Xilinx/finn/blob/main/notebooks/end2end_example/bnn-pynq/tfc_end2end_verification.ipynb) from FINN tutorials.\n",
    "\n",
    "As you will see, verification will be fairly easy as FINN provides a very user-friendly API for these tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C++ Simulation\n",
    "\n",
    "First, execute LAB2, we will grab the models from the common ```/tmp/finn_dev_yourusername/``` output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "model_cppsim = ModelWrapper(\"/tmp/finn_dev_rootmin/to_hw_conv.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the \"golden reference\" for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import qonnx.core.onnx_exec as oxe\n",
    "\n",
    "input_tensor = input_a = np.random.uniform(low=0, high=255, size=(28*28)).astype(np.uint8).astype(np.float32)\n",
    "input_dict = {\"global_in\": input_tensor.reshape(1,28*28)}\n",
    "golden_model = ModelWrapper(\"/tmp/finn_dev_rootmin/full_preproc.onnx\")\n",
    "output_dict = oxe.execute_onnx(golden_model, input_dict)\n",
    "golden_output = output_dict[list(output_dict.keys())[0]]\n",
    "\n",
    "print(golden_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate the different source code : ```PrepareCppSim``` and executables : ```CompileCppSim```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from qonnx.transformation.general import GiveUniqueNodeNames\n",
    "\n",
    "model_cppsim = model_cppsim.transform(GiveUniqueNodeNames())\n",
    "model_cppsim = model_cppsim.transform(PrepareCppSim())\n",
    "model_cppsim = model_cppsim.transform(CompileCppSim())\n",
    "\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "\n",
    "model_cppsim.save(\"/tmp/finn_dev_rootmin/cppsim.onnx\")\n",
    "showInNetron(\"/tmp/finn_dev_rootmin/cppsim.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph manipulation reminder : [cutomOp Docs](https://finn.readthedocs.io/en/latest/source_code/finn.custom_op.html#module-qonnx.custom_op.registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the generated files\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "\n",
    "model = ModelWrapper(\"/tmp/finn_dev_rootmin/cppsim.onnx\")\n",
    "\n",
    "fc0 = model.graph.node[0]\n",
    "fc0w = getCustomOp(fc0)\n",
    "cpp_code_dir = fc0w.get_nodeattr(\"code_gen_dir_cppsim\")\n",
    "\n",
    "!ls {cpp_code_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "\n",
    "model_cppsim = model_cppsim.transform(SetExecMode(\"cppsim\"))\n",
    "model_cppsim.save(\"/tmp/finn_dev_rootmin/cppsim_exec.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnx.numpy_helper as nph\n",
    "import qonnx.core.onnx_exec as oxe\n",
    "\n",
    "input_dict = {\"global_in\": input_tensor.reshape(1,28*28)}\n",
    "\n",
    "parent_model = ModelWrapper(\"/tmp/finn_dev_rootmin/df_part.onnx\")\n",
    "sdp_node = parent_model.graph.node[0]\n",
    "child_model = \"/tmp/finn_dev_rootmin/cppsim_exec.onnx\"\n",
    "getCustomOp(sdp_node).set_nodeattr(\"model\", child_model)\n",
    "output_dict = oxe.execute_onnx(parent_model, input_dict)\n",
    "output_cppsim = output_dict[list(output_dict.keys())[0]]\n",
    "\n",
    "try:\n",
    "    print(golden_output, output_cppsim)\n",
    "    assert np.isclose(output_cppsim, np.where(golden_output==np.amax(golden_output)), atol=1e-3).all()\n",
    "    print(\"Results are the same!\")\n",
    "except AssertionError:\n",
    "    assert False, \"The results are not the same!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great results are the same ! Note that this very small exmaple was done as an example and compares simple top label output. You can use the exmaple in a loop to check for hundreds of random sample et even setup a dataloader and testing loop for verification like we did like in LAB2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

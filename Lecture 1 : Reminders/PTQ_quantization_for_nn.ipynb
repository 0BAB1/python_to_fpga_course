{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization for Neural Networks\n",
    "\n",
    "After the small asymetric quantization example, In this notebook, we will see how to quantize a Neural Network (NN).\n",
    "\n",
    "## Post Training Quantization (PTQ)\n",
    "\n",
    "The PQT will involve training a regular model and then quantizing it.\n",
    "\n",
    "To do so, we will use observer to determine alpha, beta, scale and zero factors, whilst simply running inference. Just like we did in the f32 to int8 vector quantization example.\n",
    "\n",
    "This will be done using pytorch only.\n",
    "\n",
    "## Quantization Aware Training (QAT)\n",
    "\n",
    "For this, you will have to wait until the the **next lecture**, where we will use Brevitas, a superset of pytorch, to do QAT\n",
    "\n",
    "### Side note on Pytorch vs Brevitas for Quantization\n",
    "\n",
    "Note that other framework than brevitas exists for QAT but FINN (a very important tool for later in the course) was built for working with Brevitas.\n",
    "\n",
    "*Meaning* : even though we use PyTorch here as it is the easiest for PQT, we will quickly transition to brevitas for QAT. See this notebook serve as learning material to demonstrate that you can also you quantization for simpler AI use cases to save inference costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT THE DATA\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE MODEL\n",
    "# This example will be more elaborated in the second lecture, along side a full QAT example in Brevitas\n",
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECLARE THE MODEL AND OPTIMIZATION PARAMETERS\n",
    "import torch.optim as optim\n",
    "\n",
    "model = SimpleClassifier()\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL\n",
    "for epoch in range(5):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Flatten the image\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/5], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "import torch\n",
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        # Flatten the image\n",
    "        data = data.reshape(-1, 28*28)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "accuracy = 100. * correct / len(test_loader.dataset)\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "old_accuracy = accuracy #save for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW LET'S ANALYSE !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# GET MODEL SIZE\n",
    "def get_size(model):\n",
    "    torch.save(model.state_dict(), \"model_before_PTQ.p\")\n",
    "    size = os.path.getsize(\"model_before_PTQ.p\")/1e3\n",
    "    os.remove(\"model_before_PTQ.p\")\n",
    "    return(size)\n",
    "\n",
    "old_size = get_size(model)\n",
    "print(\"size of the model before PTQ : \", old_size, \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POST TRAINING QUANT\n",
    "\n",
    "When we did the quantization example, we saw that we use min and max valus to compute adequate quantization.\n",
    "\n",
    "Here inputs changes all the time ! we have to run inference to gather data in order to determine the best parameters.\n",
    "\n",
    "To do this, we will simply use \"Obervers\"\n",
    "\n",
    "## Crerate a model with observers\n",
    "\n",
    "first we add quant and dequant [stubs](https://pytorch.org/docs/stable/generated/torch.ao.quantization.QuantStub.html) wich are observers for broad I/O quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE MODEL\n",
    "\n",
    "class SimpleQuantClassifier(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(SimpleQuantClassifier, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.quant(x)\n",
    "        out = self.model(out)\n",
    "        out = self.dequant(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and add observers to intermediate layers too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.ao.quantization\n",
    "\n",
    "\n",
    "quant_model = SimpleQuantClassifier()\n",
    "quant_model.load_state_dict(model.state_dict()) # load pre-trained weights into the quant model\n",
    "quant_model.eval()\n",
    "\n",
    "quant_model.qconfig = torch.ao.quantization.default_qconfig\n",
    "quant_model = torch.ao.quantization.prepare(quant_model) # insert observers\n",
    "quant_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference on the new model\n",
    "\n",
    "This will allow observer to gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "quant_model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        # Flatten the image\n",
    "        data = data.reshape(-1, 28*28)\n",
    "        output = quant_model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "accuracy = 100. * correct / len(test_loader.dataset)\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now re check our model, we now see that observers carry data with them, good !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize the model\n",
    "\n",
    "We can now simply use othe pytorch API to use these data for quantization !\n",
    "\n",
    "we than visualize our weights, they are now INT8 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.ao.quantization\n",
    "\n",
    "quant_model = torch.ao.quantization.convert(quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.int_repr(quant_model.model[0].weight()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare quantized and dequantized weights, we can see that a small error has been introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.model[0].weight)            # original weights\n",
    "print(quant_model.model[0].weight())    # dequant weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets compare again !\n",
    "\n",
    "we will now analyse accuracy and size of the model. (/4 theorically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "quant_model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        # Flatten the image\n",
    "        data = data.reshape(-1, 28*28)\n",
    "        output = quant_model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "accuracy = 100. * correct / len(test_loader.dataset)\n",
    "print(f'Test Accuracy (ORIGINAL): {old_accuracy:.2f}%')\n",
    "print(f'Test Accuracy (Quantized): {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"size of the model before PTQ : \", old_size, \"KB\")\n",
    "print(\"size of the model after PTQ : \", get_size(quant_model), \"KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
